{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1Vz4nFm9Wfaxl5yvCtBygAhP7rTmuUtLQ","authorship_tag":"ABX9TyM0v7qBi6CTAQ/Bibq+I7eb"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!pip install tensorflow"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zZrM0iBDVQLr","executionInfo":{"status":"ok","timestamp":1709159553139,"user_tz":-60,"elapsed":10527,"user":{"displayName":"Manas Singh","userId":"10440960304052377350"}},"outputId":"33715a29-57dc-4cd7-ce9c-7df8a02e4ef1"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n","Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.2)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.9.0)\n","Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.36.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.60.1)\n","Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n","Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n","Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n","Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.5.2)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.1)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.2.2)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.5.1)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-zMekabw6J9I"},"outputs":[],"source":["import pandas as pd\n","import os\n","import numpy as np\n","\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.optimizers import Adam"]},{"cell_type":"code","source":["medium_data = pd.read_csv('/content/drive/MyDrive/medium_data.csv')\n","medium_data.head()"],"metadata":{"id":"v-kppoGES8B8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('Number of records: ', medium_data.shape[0])\n","print('Number of fields: ', medium_data.shape[1])"],"metadata":{"id":"Wy3FtmARWzFb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["medium_data['title']"],"metadata":{"id":"zOk_bn_IXRRe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#the lambda function takes each title (referred to as X) and replaces occurrences of the unicode character \\xaO with standard space\n","medium_data['title'] = medium_data['title'].apply(lambda x: x.replace(u'\\xa0', u' '))\n","medium_data['title'] = medium_data['title'].apply(lambda x: x.replace('\\u200a', ' '))"],"metadata":{"id":"XpXPHJJeXZeN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenizer = Tokenizer(oov_token='<oov>')\n","tokenizer.fit_on_texts(medium_data['title'])\n","total_words = len(tokenizer.word_index) + 1\n","\n","print(\"Total number of words: \", total_words)\n","print(\"Word: ID\")\n","print(\"------------------\")\n","print(\"<oov>: \", tokenizer.word_index['<oov>'])\n","print(\"Strong: \", tokenizer.word_index['strong'])\n","print(\"And: \", tokenizer.word_index['and'])\n","print(\"Consumption: \", tokenizer.word_index['consumption'])"],"metadata":{"id":"vpGpCVxSYTh6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["input_sequences = []\n","for line in medium_data['title']:\n","  token_list = tokenizer.texts_to_sequences([line])[0]\n","  #print(token_list)\n","\n","  for i in range(1,len(token_list)):\n","    n_gram_sequence = token_list[:i+1]\n","    input_sequences.append(n_gram_sequence)\n","\n","#print(input_sequences)\n","print('Total input sequences: ', len(input_sequences))"],"metadata":{"id":"HYx_LXbzZ6ER"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["max_sequence_len = max([len(x) for x in input_sequences])\n","input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n","input_sequences[1]"],"metadata":{"id":"rmKqPAc_bnAm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#create features and label\n","xs, labels = input_sequences[:,:-1], input_sequences[:,-1]\n","ys = tf.keras.utils.to_categorical(labels, num_classes=total_words)\n","\n","print(xs[5])\n","print(labels[5])\n","print(ys[5][14])"],"metadata":{"id":"EGTWtiACdBQ2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = Sequential()\n","model.add(Embedding(total_words, 100, input_length=max_sequence_len-1))\n","model.add(Bidirectional(LSTM(150)))#150 specifies the number of units (or neurons) in the LSTM layer that is being used in a bidirectional\n","model.add(Dense(total_words, activation='softmax'))\n","adam = Adam(lr=0.01)\n","model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n","history = model.fit(xs, ys, epochs=50, verbose=1)\n","#print model.summary()\n","print(model)"],"metadata":{"id":"n0BTDZ8Vdrve"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#predicting the next word of the title\n","seed_text = 'implementation of'\n","next_words = 2\n","\n","for _ in range(next_words):\n","  token_list = tokenizer.texts_to_sequences([seed_text])[0]\n","  token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n","  predicted_probs = model.predict(token_list, verbose=0)\n","  predicted = np.argmax(predicted_probs, axis=-1)\n","  output_word = \"\"\n","  for word, index in tokenizer.word_index.items():\n","    if index == predicted:\n","      output_word = word\n","      break\n","  seed_text += \" \" + output_word\n","print(seed_text)"],"metadata":{"id":"LMguCAhWgNpH"},"execution_count":null,"outputs":[]}]}